{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44acde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import re\n",
    "res_digit = r'[0-9]'\n",
    "\n",
    "# fourier transform\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832db706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a hack to make the library in the parent folder available for imoprts\n",
    "# A better solution is by np8 here:\n",
    "# https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "thisdir = sys.path[0]\n",
    "print(f\"thisdir = {thisdir}\")\n",
    "parentdir = os.path.dirname(thisdir)\n",
    "#print(f\"parentdir = {parentdir}\")\n",
    "if not parentdir in sys.path:\n",
    "    print(\"Adding parent directory to python path\")\n",
    "    sys.path.insert(1, parentdir)\n",
    "else:\n",
    "    print(\"Skipping adding parent direct to path (there already)\")\n",
    "\n",
    "print(f\"sys.path =\\n{sys.path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f17581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure relative path to data directory is sound\n",
    "# for the notebook we need to modify the BASE_DATA_FOLDER\n",
    "import os \n",
    "os.environ['PREDICAMENT_DATA_DIR'] =  '../data'\n",
    "\n",
    "from predicament.utils.config import DREEM_EEG_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd724667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predicament.data.timeseries import create_participant_data_edf_only\n",
    "from predicament.data.windowed import window_all_participants_data\n",
    "from predicament.data.windowed import merge_condition_data\n",
    "from predicament.data.partitioning import between_subject_cv_partition\n",
    "\n",
    "from predicament.data.features import MAXIMAL_FEATURE_GROUP\n",
    "from predicament.data.features import STATS_FEATURE_GROUP\n",
    "from predicament.data.features import INFO_FEATURE_GROUP\n",
    "from predicament.data.features import FREQ_FEATURE_GROUP\n",
    "from predicament.data.features import convert_timeseries_to_features\n",
    "from prepare_evaluation_data import load_dataframe_and_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e1a17",
   "metadata": {},
   "source": [
    "## Load featured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df, featured_config = load_dataframe_and_config(\n",
    "    '../data/featured/20231206193533/', 'featured.csv')\n",
    "data_format = featured_config['LOAD']['data_format']\n",
    "print(f\"data_format: {data_format}\")\n",
    "n_channels = int(featured_config['LOAD']['n_channels'])\n",
    "channels = json.loads(featured_config['LOAD']['channels'].replace(\"'\",'\"'))\n",
    "participant_list = json.loads(featured_config['LOAD']['participant_list'].replace(\"'\",'\"'))\n",
    "Fs = int(featured_config['LOAD']['sample_rate'])\n",
    "window_size = int(featured_config['LOAD']['window_size'])\n",
    "window_step = int(featured_config['LOAD']['window_step'])\n",
    "time = window_size/Fs\n",
    "print(f\"Fs: {Fs}, n_samples = {window_size}, time: {time}s, n_channels: {n_channels}\")\n",
    "window_overlap_factor = window_size//window_step\n",
    "print(f\"window_size: {window_size}, window_step: {window_step}, window_overlap_factor: {window_overlap_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = set(\n",
    "    ['Mean', 'SD', 'MAD', 'Max', 'Min',# 'SMA',\n",
    "      'Energy', 'IQR', # 'Entropy',\n",
    "     'arCoeff', 'Correlation', 'MaxFreqInd', 'MeanFreq', 'FreqSkewness',\n",
    "    'FreqKurtosis' # , 'EnergyBands'\n",
    "    ])\n",
    "columns_to_use = [ col for col in featured_df.columns if re.sub(res_digit, '', col) in features_to_use ]\n",
    "print(f\"columns_to_use = {columns_to_use}\")\n",
    "\n",
    "designmtx = featured_df[columns_to_use].values \n",
    "condition_data = featured_df['condition'].values.astype(int)\n",
    "subject_data_names = featured_df['participant']\n",
    "\n",
    "design2d = TSNE(n_components=2, init='random', perplexity=3).fit_transform(designmtx)\n",
    "print(f\"design2d.shape = {design2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.unique(subject_data_names)\n",
    "subject_data = np.empty(subject_data_names.shape, dtype=int)\n",
    "for s, sub in enumerate(subjects):\n",
    "    subject_data[subject_data_names==sub] = s\n",
    "print(f\"designmtx.shape = {designmtx.shape}\")\n",
    "print(f\"condition_data.shape = {condition_data.shape}\")\n",
    "print(f\"subject_data.shape = {subject_data.shape}\")\n",
    "    \n",
    "conditions = np.unique(condition_data)\n",
    "markers = ['v', '^', '<', '>', 's', '*', '+' , 'x', 'D', '.']\n",
    "colours = ['b','g','r','y','k']\n",
    "cmap = plt.cm.rainbow\n",
    "norm = colors.BoundaryNorm(np.arange(np.min(subject_data)-0.5,np.max(subject_data)+0.5), cmap.N)\n",
    "\n",
    "plt.scatter(\n",
    "    design2d[:,0], design2d[:,1], c=subject_data, norm=norm, s=0.5, edgecolor='none')\n",
    "plt.colorbar(\n",
    "    ticks=np.arange(subjects.size))\n",
    "plt.title(\"2d TSNE data coloured by subject id\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "cmap = plt.cm.rainbow\n",
    "norm = colors.BoundaryNorm(np.arange(np.min(condition_data)-0.5,np.max(condition_data)+0.5), cmap.N)\n",
    "\n",
    "plt.scatter(\n",
    "    design2d[:,0], design2d[:,1], c=condition_data, norm=norm, s=0.5, edgecolor='none')\n",
    "plt.colorbar(\n",
    "    ticks=np.arange(conditions.size))\n",
    "plt.title(\"2d TSNE data coloured by condition id\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d5d96",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        min_samples_leaf=5, random_state=0\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        max_leaf_nodes=15, random_state=0\n",
    "    ),\n",
    "    \"MLP\":  MLPClassifier(max_iter=100)\n",
    "}\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\"n_estimators\": [10, 20, 50, 100]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [10, 20, 50, 100]},\n",
    "    \"MLP\": {\n",
    "        'hidden_layer_sizes': [(10,),(20,),(50,),(100,)],\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standard cross-validation\n",
    "# # Match all digits in the string and replace them with an empty string\n",
    "# # new_string = re.sub(pattern, '', string1)\n",
    "# results_df = None\n",
    "\n",
    "# features_to_use = set(\n",
    "#     ['Mean', 'SD', 'MAD', 'Max', 'Min',# 'SMA',\n",
    "#       'Energy', 'IQR', # 'Entropy',\n",
    "#      'arCoeff', 'Correlation', 'MaxFreqInd', 'MeanFreq', 'FreqSkewness',\n",
    "#     'FreqKurtosis' # , 'EnergyBands'\n",
    "#     ])\n",
    "# columns_to_use = [ col for col in featured_df.columns if re.sub(res_digit, '', col) in features_to_use ]\n",
    "# print(f\"columns_to_use = {columns_to_use}\")\n",
    "\n",
    "# designmtx = featured_df[columns_to_use].values \n",
    "# # condition_data = featured_df['condition'].values.astype(int)\n",
    "# # subject_data = featured_df['subject'].values.astype(int)\n",
    "\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# results = []\n",
    "# for name, model in models.items():\n",
    "#     grid_search = GridSearchCV(\n",
    "#         estimator=model,\n",
    "#         param_grid=param_grids[name],\n",
    "#         return_train_score=True,\n",
    "#         cv=cv,\n",
    "#     ).fit(designmtx, condition_data)\n",
    "#     result = {\"model\": name, \"cv_results\": pd.DataFrame(grid_search.cv_results_)}\n",
    "#     results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"results[0]['mean_test_score'] ={results[0]['mean_test_score']}\")\n",
    "# print(f\"results[1]['mean_test_score'] ={results[1]['mean_test_score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114ed51",
   "metadata": {},
   "source": [
    "## Hold one group out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard cross-validation\n",
    "# Match all digits in the string and replace them with an empty string\n",
    "# new_string = re.sub(pattern, '', string1)\n",
    "subjects = np.unique(featured_df['participant'])\n",
    "n_subjects = len(subjects)\n",
    "groups = np.empty(len(featured_df), dtype=int)\n",
    "for s, sub in enumerate(subjects):\n",
    "    groups[featured_df['participant']==sub] = s\n",
    "    \n",
    "features_to_use = set(\n",
    "    ['Mean', 'SD', 'MAD', 'Max', 'Min',# 'SMA',\n",
    "      'Energy', 'IQR', # 'Entropy',\n",
    "     'arCoeff', 'Correlation', 'MaxFreqInd', 'MeanFreq', 'FreqSkewness',\n",
    "    'FreqKurtosis' # , 'EnergyBands'\n",
    "    ])\n",
    "columns_to_use = [ col for col in featured_df.columns if re.sub(res_digit, '', col) in features_to_use ]\n",
    "print(f\"columns_to_use = {columns_to_use}\")\n",
    "\n",
    "designmtx = featured_df[columns_to_use].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "group_kfold = GroupKFold(n_splits=n_subjects)\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        return_train_score=True,\n",
    "        cv=group_kfold,\n",
    "    ).fit(X=designmtx, y=condition_data, groups=groups)\n",
    "    result_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    #test_df['model'] = result['model']\n",
    "    result_df.insert(0, 'model', name)\n",
    "    result_df.insert(1, 'held out', 'subject')\n",
    "    result_df.insert(2, 'feature set', str(features_to_use))\n",
    "    display(result_df)\n",
    "    results_df = pd.concat((results_df, result_df))\n",
    "    #result = {\"model\": name, \"cv_results\": pd.DataFrame(grid_search.cv_results_)}\n",
    "    #results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4238d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099700fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "nowstr = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "results_df.to_csv(f'../data/results/{nowstr}_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbe0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'MLP']['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc29b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'Random Forest']['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['model'] == 'Gradient Boosting']['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf023ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(results_df[results_df['mean_test_score'] == 0.3252334560211044]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcffeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25792fa",
   "metadata": {},
   "source": [
    "## Held out subject-conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74133dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_conditions = [(s,c) for s in subjects for c in conditions]\n",
    "subject_conditions\n",
    "featured_df['subject_conditions'] = None\n",
    "for i, (s, c) in enumerate(subject_conditions):\n",
    "    featured_df['subject_conditions'][(featured_df['participant'] == s) & (featured_df['condition'] == c)] = i\n",
    "featured_df['subject_conditions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_groups = featured_df['subject_conditions'].to_numpy()\n",
    "sc_results_df = pd.DataFrame()\n",
    "sc_group_kfold = GroupKFold(n_splits=n_subjects)\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        return_train_score=True,\n",
    "        cv=sc_group_kfold,\n",
    "    ).fit(X=designmtx, y=condition_data, groups=sc_groups)\n",
    "    result_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    #test_df['model'] = result['model']\n",
    "    result_df.insert(0, 'model', name)\n",
    "    result_df.insert(1, 'held out', 'subject_condition')\n",
    "    result_df.insert(2, 'feature set', str(features_to_use))\n",
    "    display(result_df)\n",
    "    sc_results_df = pd.concat((sc_results_df, result_df))\n",
    "    #result = {\"model\": name, \"cv_results\": pd.DataFrame(grid_search.cv_results_)}\n",
    "    #results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412728f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "nowstr = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "results_df.to_csv(f'../data/results/{nowstr}_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in np.unique(sc_results_df['model']):\n",
    "    model_max_test_score = sc_results_df[sc_results_df['model'] == model]['mean_test_score'].max()\n",
    "    print(f\"{model}: max_test_score= {model_max_test_score}\")\n",
    "    d = sc_results_df[sc_results_df['mean_test_score'] == model_max_test_score]['params']\n",
    "    for k,v in d.items():\n",
    "        model_best_params = v\n",
    "        print(f\"best params: {v}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bf65d",
   "metadata": {},
   "source": [
    "## Held out subject-condition-phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eeed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in subjects:\n",
    "    for condition in conditions:\n",
    "        _filter = (featured_df['condition'] == condition) & (featured_df['participant'] == participant)\n",
    "        sc_featured_df = featured_df[_filter]\n",
    "        min_time_index = sc_featured_df['start time'].min() \n",
    "        max_time_index = sc_featured_df['start time'].max()\n",
    "        mid_time_index = (min_time_index+max_time_index)//2\n",
    "        margin = window_overlap_factor//2\n",
    "        if (margin*2) < window_overlap_factor:\n",
    "            margin += 1\n",
    "        phase1_start_index = min_time_index\n",
    "        phase1_end_index = mid_time_index-margin\n",
    "        phase2_start_index = mid_time_index+margin\n",
    "        phase2_end_index = max_time_index\n",
    "        print(f\"participant: {participant}, condition: {condition}\")\n",
    "        print(f\"min: {min_time_index}, max: {max_time_index}, mid: {mid_time_index}\")\n",
    "        if phase1_start_index < phase1_end_index:\n",
    "            print(f\"phase1_start_index: {phase1_start_index}, phase1_end_index: {phase1_end_index}\")\n",
    "            print(f\"phase2_start_index: {phase2_start_index}, phase2_end_index: {phase2_end_index}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52749166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = len(featured_df)\n",
    "for c in np.unique(featured_df['condition']):\n",
    "    count = len(featured_df[featured_df['condition'] == c])\n",
    "    print(f\"count = {count}\")\n",
    "    print(f\"{c} : {count}/{tot} = {count/tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ccdcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
