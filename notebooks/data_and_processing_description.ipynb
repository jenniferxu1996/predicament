{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd84a94",
   "metadata": {},
   "source": [
    "# Collected Data\n",
    "\n",
    "$\\newcommand{\\reals}{\\mathbb{R}}$\n",
    "$\\newcommand{\\participants}{\\mathcal{I}}$\n",
    "$\\newcommand{\\conditions}{\\mathcal{C}}$\n",
    "$\\newcommand{\\nullconditions}{\\conditions_{\\text{null}}}$\n",
    "$\\newcommand{\\channels}{\\mathcal{H}}$\n",
    "$\\newcommand{\\dreemtok}{\\texttt{DREEM}}$\n",
    "$\\newcommand{\\efourtok}{\\texttt{E4}}$\n",
    "$\\newcommand{\\eegtok}{\\texttt{EEG}}$\n",
    "$\\newcommand{\\traintok}{\\texttt{train}}$\n",
    "$\\newcommand{\\testtok}{\\texttt{test}}$\n",
    "$\\newcommand{\\cvtok}{\\texttt{cv}}$\n",
    "\n",
    "$\\newcommand{\\timeclock}{\\tau}$\n",
    "$\\newcommand{\\bufferinterval}{\\Delta\\timeclock}$\n",
    "$\\newcommand{\\rectimeclock}{\\tilde{\\timeclock}}$\n",
    "$\\newcommand{\\starttimeclock}[1]{\\timeclock^{\\circ}_{#1}}$\n",
    "$\\newcommand{\\endtimeclock}[1]{\\timeclock^{\\bullet}_{#1}}$\n",
    "$\\newcommand{\\recstarttimeclock}[1]{\\rectimeclock^{\\circ}_{#1}}$\n",
    "$\\newcommand{\\recendtimeclock}[1]{\\rectimeclock^{\\bullet}_{#1}}$\n",
    "$\\newcommand{\\starttime}[1]{t^{\\circ}_{#1}}$\n",
    "$\\newcommand{\\endtime}[1]{t^{\\bullet}_{#1}}$\n",
    "$\\newcommand{\\duration}[1]{T_{#1}}$\n",
    "$\\newcommand{\\samplerate}{{f}}$\n",
    "$\\newcommand{\\channelsamplerate}[1]{\\samplerate^{(#1)}}$\n",
    "$\\newcommand{\\channeldata}[2]{u_{#1}^{(#2)}}$\n",
    "$\\newcommand{\\windowvec}[1]{x_{#1}}$\n",
    "$\\newcommand{\\windowmtx}[1]{X_{#1}}$\n",
    "$\\newcommand{\\windowtensor}[1]{x_{#1}}$\n",
    "$\\newcommand{\\channelwindowvec}[2]{\\windowvec{#1}^{(#2)}}$\n",
    "$\\newcommand{\\channelwindowmtx}[2]{\\windowmtx{#1}^{(#2)}}$\n",
    "\n",
    "We have the following data. Each participant $i \\in \\participants$ took part in an experiment of type $m$, giving the experimental instance $e=(i,m)$. For current purposes, we refer to $e=(i, m)$ as $i$ without ambiguity, as each participant only took part in one experiment. Each participant $i$'s experiment, had a start time $\\starttimeclock{i}$, and an end time $\\endtimeclock{i}$ a duration of $\\duration{i}= \\endtimeclock{i}-\\starttimeclock{i}$ and gathered data along a number of channels $h \\in \\channels$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2babd0",
   "metadata": {},
   "source": [
    "## conditions\n",
    "\n",
    "Each participant has data recorded while taking part in one or more conditions. The conditions of interest are:\n",
    "\\begin{align}\n",
    "\\conditions = \\{\n",
    "\\texttt{familiar-music}, \\texttt{wildlife-video}, \\texttt{family-inter}, \\texttt{tchaikovsky}, \\texttt{exper-video}, \\texttt{familiar-music-2}\n",
    "\\}\n",
    "\\end{align}\n",
    "\n",
    "There are also some other conditions which we arent currently investigating:\n",
    "\\begin{align}\n",
    "\\nullconditions = \\{\n",
    "\\texttt{setup}, \\texttt{baseline}, \\texttt{baseline-BIS}, \\texttt{takeoff-EEG}, \\texttt{break} ,\\ldots\n",
    "\\}\n",
    "\\end{align}\n",
    "\n",
    "Conditions are mutually exclusive, in that only one can be experienced at any one time. In the current experimental set up, they each only occur once per participant experiment. If a second condition  with similar features occurs a second time, this is given a different condition tag, e.g. `familiar_music` and `familiar_music_2`. Data in `<EXPDATADIR>/event_details.csv` lists each condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a89f2",
   "metadata": {},
   "source": [
    "## channels\n",
    "\n",
    "These channels can be split into those collected by the DREEM EEG device $\\channels_{\\dreemtok}$ and those collected by the E4 device $\\channels_{\\efourtok}$. For our current data, the following channels are present:\n",
    "\\begin{align}\n",
    "\\channels_{\\dreemtok} \n",
    "& = [\n",
    "\\texttt{Accelero Norm}, \\texttt{EEG Fpz-O1}, \\texttt{EEG Fpz-O2}, \\texttt{EEG Fpz-F7}, \\texttt{EEG F8-F7}, \\texttt{EEG F7-01}, \\texttt{EEG F8-O2}, \\texttt{EEG Fpz-F8}, \\texttt{Positiongram}, \\texttt{PulseOxy Infrare}, \\texttt{PulseOxy Red Hea}, \\texttt{Respiration x}, \\texttt{Respiration y}, \\texttt{Respiration z}]\n",
    "\\\\\n",
    "\\channels_{\\efourtok}\n",
    "&= [\n",
    "\\texttt{ACC}, \\texttt{BVP}, \\texttt{EDA}, \\texttt{HR}, \\texttt{IBI}, \\texttt{TEMP}]\n",
    "\\end{align}\n",
    "\n",
    "In preliminary experiments, two subsets of the DREEM channels were identified as potentially important for prediction from EEG signals. These denoted:\n",
    "\\begin{align}\n",
    "\\channels_{\\eegtok 1} \n",
    "& = [\n",
    "\\texttt{EEG Fpz-O1}, \\texttt{EEG Fpz-O2}, \\texttt{EEG Fpz-F7}, \\texttt{EEG F8-F7}, \\texttt{EEG F7-01}, \\texttt{EEG F8-O2}, \\texttt{EEG Fpz-F8}\n",
    "]\n",
    "\\\\\n",
    "\\channels_{\\eegtok 2}\n",
    "&= [\n",
    "\\texttt{EEG Fpz-O1}, \\texttt{EEG Fpz-O2}, \\texttt{EEG F8-F7}, \\texttt{EEG Fpz-F8}\n",
    "]\n",
    "\\end{align}\n",
    "The first of these $\\channels_{\\eegtok 1} \\subset \\channels_{\\dreemtok}$ is the complete set of EEG channels from the DREEM device. The second $\\channels_{\\eegtok 2} \\subset \\channels_{\\eegtok 1}$ is a subset of channels that were found to be sufficiently independent signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d086449",
   "metadata": {},
   "source": [
    "## participant time-series data\n",
    "\n",
    "For each participant $i$ and each channel $h$ there is a time-series of sensor readings $\\channeldata{i}{h} \\in \\reals^{K_{ih}}$ where there are $K_{ih}=\\frac{\\duration{i}}{\\samplerate^{(h)}}$ samples, such that $\\duration{i}$ is the time-duration (seconds) of the sensor readings and $\\channelsamplerate{h}$ is the sampling rate of channel $h$. Our data objects helpfully give sensor readings at the sample rate of the most frequently sampled channel, so all channels are assumed to have the same sample rate and lower sampling rate channels fill in with duplicates (to confirm), but this is not done across channel groups.\n",
    "\n",
    "For the dreem device $\\channelsamplerate{h} = 250$Hz for all channels $h \\in \\channels_{\\dreemtok}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac05202",
   "metadata": {},
   "source": [
    "## participant-condition time-series data\n",
    "\n",
    "Within an experiment, a participant will experience a sequence of conditions, in non-overlapping time periods. We denote the start and end clock-time of of condition $c$ for participant $i$ as $\\starttimeclock{ic}$ and $\\endtimeclock{ic}$ respectively. For convenience, we also define experimental times for a given clock time of $\\timeclock$ within this condition as $t=\\timeclock - \\starttimeclock{ic}$. Experimental start and end times are then at $t=0$ and $t = \\duration{ic} = \\endtimeclock{ic} - \\starttimeclock{ic}$ (which is also the duration of the condition for that participant). FOr simplicity here we assume that the clock time starts at $0$ at the beginning of a given study rather than the universal clock time.\n",
    "\n",
    "The condition times are recorded with minute accuracy by study technicians and for participant $i$ in condition $c$ recorded start and end times are respectively denoted as $\\recstarttimeclock{ic}$ and $\\recendtimeclock{ic}$. We define a standard buffer interval $\\bufferinterval$ which is used to establish more conservative start and end times as:\n",
    "\\begin{align}\n",
    "\\starttimeclock{ic} = \\recstarttimeclock{ic} + \\bufferinterval\n",
    "\\\\\n",
    "\\endtimeclock{ic} = \\recendtimeclock{ic} - \\bufferinterval\n",
    "\\end{align}\n",
    "\n",
    "In our initial experiments the buffer interval was set to $\\bufferinterval = 30$s.\n",
    "\n",
    "Sensor readings for channel $h$, participant-conditions $(i,c)$, are denoted $\\channeldata{ic}{h} \\in \\reals^{K_{ich}}$ where $K_{ich}= \\frac{\\duration{ic}}{\\channelsamplerate{h}}$. We denote the single activation at time-step $k=0, \\ldots, K_{ich}-1$ as $\\channeldata{ick}{h}$, so \n",
    "\\begin{align}\n",
    "\\channeldata{ic}{h} = \n",
    "\\left(\n",
    "\\channeldata{ic0}{h}, \\ldots, \\channeldata{ick}{h}, \\ldots,\\channeldata{ic (K_{ich}-1)}{h}\n",
    "\\right)^T\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In discussions that follow, we may wish to divide a single participant's data into train and test parts, before we perform any further processing. In that case, we will indicate test data with a tilde, e.g. $\\tilde{u}_{ic}^{(h)}$ and train  (or cross-validation) data without."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f456cb",
   "metadata": {},
   "source": [
    "## Windowing data\n",
    "\n",
    "Under certain circumstances it is convenience to process time series data into vectors of uniform length. For flexibility we define this for some general window size $W$ and stride length $S$. For a given participant $i$, condition $c$ and channel $h$ we define the $j$th channel-specific windowed data vector as $\\channelwindowvec{icj}{h} \\in \\reals^{W}$. \n",
    "\n",
    "In the simplest case, we start the first vector at the first time-step ($k=0$) and take each subsequent vector starting from $S$ time-steps later in the time-series, with the last vector being the last time index $k=JS$ (integer $J$) such that there are at least $W$ time-steps remaining in the sequence, i.e. the largest $J$ such that $K_{ich}-W \\geq JS$. Thus, we have $J$ channel-specific windowed data vectors, indexed by $j = 0, \\ldots J-1$, where\n",
    "\\begin{align}\n",
    "\\channelwindowvec{icj}{h}\n",
    "=\n",
    "\\left(\n",
    "\\channeldata{ic (jS)}{h}, \\ldots, \\channeldata{ic (jS+W-1)}{h}\n",
    "\\right)^T \\in \\reals^{W}\n",
    "\\end{align}\n",
    "And we stack these into channel data matrices $\\channelwindowmtx{ic}{h} \\in \\reals^{J\\times W}$ where\n",
    "\\begin{align}\n",
    "\\channelwindowmtx{ic}{h}\n",
    "=\n",
    "\\left(\n",
    "\\channelwindowvec{ic0}{h}, \\channelwindowvec{ic1}{h}, \\ldots, \\channelwindowvec{ic(J-1)}{h}\n",
    "\\right)^T \n",
    "\\end{align}\n",
    "So the $j$th row of $\\channelwindowmtx{ic}{h}$ is row vector $\\left(\\channelwindowvec{ic1}{h}\\right)^T$.\n",
    "\n",
    "### Time window durations\n",
    "\n",
    "For a given channel, $h$, and window-size (in steps) $W$ we can calculate the time-duration of the window as $T^{(h)}(W) = W/\\channelsamplerate{h}$. Equally, we can invert this operation. Given a desired time-duration, $T$, for our windowed data, we can calculate our time-window steps as $W^{(h)}(T) = T\\cdot\\channelsamplerate{h}$. Similarly, the stride for channel $h$ will depend on the sample rate too.\n",
    "\n",
    "In most cases, all channels have the same frequency, and so the window width for one channel will correspond to the same time duration as an equivalent window width for another. In cases, where sample frequencies between two channels, $h$ and $h'$ differ, we will choose window widths (and strides) that correspond to the same time-duration (where possible). In cases where there is no good integer correspondance we may also have to interpolate, one or other time-series, in order to properly align windows from different channels. For clarity and simplicity, the details of this are omitted from the subsequent discussion. Instead, we will assume that, each channel $h$ has been time-windowed with an appropriate window-size $W(h)$ and stride $S(h)$, such that the $j$th row of channel $h$ matrix $\\channelwindowmtx{ic}{h}$,  corresponds to the same time-period as the $j$th row of channel $h'$ matrix $\\channelwindowmtx{ic}{h'}$ for all pairs of channels $h$ and $h'$ under consideration.\n",
    "\n",
    "\n",
    "### Flattening channels\n",
    "\n",
    "In cases where we aim to construct data vectors that, for some participant $i$ and condition $c$,  collects together multiple channels, say from a set $\\channels$, in an unstructured way, then we can horizontally concatenate our individual channel vectors. In matrix form, this leads to the data matrix $\\channelwindowmtx{ic}{\\channels}$, or $\\windowmtx{ic}$ where the channel set $\\channels$ is clear from context. In block matrix notation:\n",
    "\\begin{align}\n",
    "\\windowmtx{ic}\n",
    "= \n",
    "\\left( \n",
    "\\channelwindowmtx{ic}{h_1}, \\channelwindowmtx{ic}{h_2}\\ldots, \\channelwindowmtx{ic}{h_{H}}\n",
    "\\right)\n",
    "\\end{align}\n",
    "where $H = \\lvert \\channels\\rvert$\n",
    "\n",
    "Assuming that the duration $T$ is such that there are good integer choices for $W(h)$ and $S(h)$ for all $h \\in \\channels$ (i.e. no interpolation is required), then this matrix with have dimensions $\\windowmtx{ic} \\in \\reals^{J \\times W(\\channels)}$ where $W(\\channels) = \\sum_{h \\in \\channels} W(h)$ and $J = \\arg\\max_{j} \\left[ jS(h)+W(h) \\leq K_{ich}\\right]$ (for any/all choices of $h$). This will always be possible when all channels are sampled at the same frequency.\n",
    "\n",
    "\n",
    "### Tensor representations of windowed data\n",
    "\n",
    "Some models will take advantage of the time-series information present in the data. In those cases, it is helpful to retain the time alignment of sensor readings across channels. For this we assume that all data is sampled at the same frequency (or interpolated so that it can be treated as though it is), and that channel matrices $\\channelwindowmtx{ic}{h}$ have the same dimension for all channels $h \\in \\channels$ (given some participant $i$ and channel $c$. We can then stack the channel window matrices as slices of a tensor. That is we define the tensor $\\windowtensor{ic} \\in \\reals^{J\\times W\\times H}$ where element $[\\windowtensor{ic}]_{(j,w,h)}$ is the $j$th row, of the $w$th window element of the $h$th channel. \n",
    "\n",
    "As this is a common set up, and we wish to compare methods that use this set up with those that don't we restrict outselves to data that can be reshaped from a vector to a matrix of $W\\times H$. However, we need to store this information alongside the data (which will be stored as matrices with a flat rows for each data-point).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d346cb0e",
   "metadata": {},
   "source": [
    "## Implementations for time-series data\n",
    "\n",
    "The functions that generate particular data representations are shown in the code below.\n",
    "\n",
    "----------------------\n",
    "| data | original function name | refactored function name | \n",
    "-------------------------------------------------------------------------\n",
    "| 1 |\n",
    "| 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62724e04",
   "metadata": {},
   "source": [
    "### Original code\n",
    "\n",
    "#### Stored data representations\n",
    "\n",
    "| name | mathematical notation | variable name | module |\n",
    "| :-------: | :------: | :-----------: | :----: |\n",
    "| DREEM_channels | $\\channels_{\\dreemtok}$ | `?` | `?` |\n",
    "| E4 channels | $\\channels_{\\efourtok}$ | `?` | `?` |\n",
    "| sample rate for h | $\\channelsamplerate{h}$ | `VG_Hz` | `?` |\n",
    "| experimental conditions | $\\conditions$ | `event_list_EEGDL` | `prepare_evaluation_data` |\n",
    "| buffer interval | $\\bufferinterval$ | `EEG_buffer`,`E4_buffer` | `?` |\n",
    "| Event times and types | $\\starttimeclock{ic}, \\endtimeclock{ic}$ | `Event_details` | `Event_time_details` |\n",
    "| Local times | $\\starttimeclock{ic}, \\endtimeclock{ic}$ | `Ray` | `EEG_data_obj._get_event_period_by_name` |\n",
    "| participant channel data (dreem) | $\\channeldata{i}{h}, h \\in \\channels_{\\dreemtok}$ | `EEG_data_obj.EEG_data[h]` | `Ray.EEG_data` |\n",
    "| participant channel data (E4) | $\\channeldata{i}{h}, h \\in \\channels_{\\efourtok}$ | `E4_data_class.E4_data[h]` | `Ray.E4_data` |\n",
    "| all participant channel data (dreem) | $\\{\\channeldata{i}{h}\\}_{h \\in \\channels_{\\dreemtok}}$ | `EEG_files` | `Ray.data_load_save` |\n",
    "| all participant channel data (E4) | $\\{\\channeldata{i}{h}\\}_{h \\in \\channels_{\\efourtok}}$ | `E4_files` | `Ray.data_load_save` |\n",
    "| participant-condition channel data (dreem) | $\\channeldata{ic}{h}, h \\in \\channels_{\\dreemtok}$ | `?` | `?` |\n",
    "| participant-condition channel data (E4) | $\\channeldata{ic}{h}, h \\in \\channels_{\\efourtok}$ | `?` | `?` |\n",
    "\n",
    "#### Key functions:\n",
    "\n",
    "| method/function name | module | Brief description of functionality and output |\n",
    "| :---: | :---: | :--- |\n",
    "| `set_up` | `Ray.data_load_save` | Reads in and creates appropriate representations for all participant channel data `EEG_files` and `E4_files` |\n",
    "| `read_all_VG_files` | `Ray.EEG_data` | Reads in DREEM data from file to `EEG_data_obj` objects |\n",
    "| `read_all_E4_files` | `Ray.E4_data` | Reads in E4 data from file to `E4_data_class` objects |\n",
    "| `gen_EEG_train_test_to_csv` | `prepare_evaluation_data` | Converts EEG channels from DREEM data into windowed data from time-series data in `EEG_files` and saves down to csv. |\n",
    "| `gen_EEG_traintest_to_csv_mix` | `Ray.data_load_save` | Create train and test set of windowed data, mixed within participants, from `EEG_files` dictionary |\n",
    "| `gen_EEG_traintest_to_csv_part` | `Ray.data_load_save` | Create train and test set of windowed data, partitioned between participants, from `EEG_files` dictionary |\n",
    "| `EEG_data_obj.get_EEG_by_channel_and_event` | `Ray.EEG_data` | Extract participant-condition time-series data from the object holding the participant time-series data and event details. |\n",
    "\n",
    "#### Key executables/scripts\n",
    "Directory information is given relative to the root directory of the repository.\n",
    "\n",
    "| file name | directory | Brief description of role |\n",
    "| :---: | :---: | :---- |\n",
    "| `prepare_evaluation_data_old.py` | `.` | The original file that loaded time series data, windowed it and split it for test and train (either within or between participant) and saved down to csv. The parameters of the call are hard-coded. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857017ff",
   "metadata": {},
   "source": [
    "### Refactored code:\n",
    "\n",
    "#### Stored data representations\n",
    "\n",
    "\n",
    "| name | mathematical notation | variable name | module |\n",
    "| :-------: | :------: | :-----------: | :----: |\n",
    "| DREEM_channels | $\\channels_{\\dreemtok}$ | `DREEM_EDF_CHANNELS` | `predicament.utils.config` |\n",
    "| E4 channels | $\\channels_{\\efourtok}$ | `?` | `?` |\n",
    "| sample rate for h | $\\channelsamplerate{h}$ | `VG_Hz` | `predicament.utils.config` |\n",
    "| experimental conditions | $\\conditions$ | `EEG_CONDITIONS` | `predicament.utils.config` |\n",
    "| buffer interval | $\\bufferinterval$ | `BUFFER_INTERVAL` | `predicament.utils.config` |\n",
    "| Event times and types | $\\starttimeclock{ic}, \\endtimeclock{ic}$ | `ParticipantEvents` | `predicament.data.events` |\n",
    "| participant channel data (dreem) | $\\channeldata{i}{h}, h \\in \\channels_{\\dreemtok}$ | `ParticipantData.timeseries[h]` | `predicament.data.timeseries` |\n",
    "| participant channel data (E4) | $\\channeldata{i}{h}, h \\in \\channels_{\\efourtok}$ | `?` | `?` |\n",
    "| all participant channel data (dreem) | $\\{\\channeldata{i}{h}\\}_{h \\in \\channels_{\\dreemtok}}$ | `?` | `?` |\n",
    "| all participant channel data (E4) | $\\{\\channeldata{i}{h}\\}_{h \\in \\channels_{\\efourtok}}$ | `?` | `?` |\n",
    "| participant-condition channel data (dreem) | $\\channeldata{ic}{h}, h \\in \\channels_{\\dreemtok}$ | `?` | `?` |\n",
    "| participant-condition channel data (E4) | $\\channeldata{ic}{h}, h \\in \\channels_{\\efourtok}$ | `?` | `?` |\n",
    "\n",
    "### Key functions\n",
    "\n",
    "\n",
    "\n",
    "| method/function name | module | Brief description of functionality and output |\n",
    "| :---: | :---: | :--- |\n",
    "| `set_up` | `Ray.data_load_save` | Reads in and creates appropriate representations for all participant channel data `EEG_files` and `E4_files` |\n",
    "| `read_all_VG_files` | `Ray.EEG_data` | Reads in DREEM data from file to `EEG_data_obj` objects |\n",
    "| `read_all_E4_files` | `Ray.E4_data` | Reads in E4 data from file to `E4_data_class` objects |\n",
    "| `gen_EEG_train_test_to_csv` | `prepare_evaluation_data` | Converts EEG channels from DREEM data into windowed data from time-series data in `EEG_files` and saves down to csv. |\n",
    "| `gen_EEG_traintest_to_csv_mix` | `Ray.data_load_save` | Create train and test set of windowed data, mixed within participants, from `EEG_files` dictionary |\n",
    "| `gen_EEG_traintest_to_csv_part` | `Ray.data_load_save` | Create train and test set of windowed data, partitioned between participants, from `EEG_files` dictionary |\n",
    "| `EEG_data_obj.get_EEG_by_channel_and_event` | `Ray.EEG_data` | Extract participant-condition time-series data from the object holding the participant time-series data and event details. |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Key executables/scripts\n",
    "Directory information is given relative to the root directory of the repository.\n",
    "\n",
    "| file name | directory | Brief description of role |\n",
    "| :---: | :---: | :---- |\n",
    "| `events.py` | `./predicament/data/` | Loads event information (observational data from the study and displays it in an appropriate form. Module also provides library code for this. |\n",
    "| `timeseries.py` | `./predicament/data/` | Loads timeseries data  (observational data from the study and displays it in an appropriate form. Allows functionality to partition data by condition and window data. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02dd207",
   "metadata": {},
   "source": [
    "# Preliminary experiments\n",
    "\n",
    "This describes the processing that took place for the existing/pilot experiments.\n",
    "\n",
    "## Machine learning data-matrices\n",
    "\n",
    "TBC\n",
    "\n",
    "## Test-train splits\n",
    "\n",
    "TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb2f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb51fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c75b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
