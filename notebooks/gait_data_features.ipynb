{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab621dc",
   "metadata": {},
   "source": [
    "This is a live notebook with experimental code to develop functionality for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518e95ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['debug_windowing_data.ipynb', 'logs', 'feature_development.ipynb', 'data', 'merging_dataframes.ipynb', 'data_and_processing_description.ipynb', 'featured_eeg_prediction.ipynb', 'featured_prediction_random_forest.ipynb', 'window_timings_and_IBI.ipynb', 'gait_data_exploration.ipynb', 'feature_correlation_analysis.ipynb', 'featured_eeg_prediction_gradient_boosting.ipynb', 'Analyse_results.ipynb', '.ipynb_checkpoints', 'loading_e4_data.ipynb', 'featured_E4_prediction.ipynb', 'data_investigation_scratch.ipynb', 'grouping_and_crossvalidation.ipynb', 'featured_prediction_svm.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import scipy.stats as spstats\n",
    "# fourier transform\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from statsmodels.tsa.api import acf, graphics, pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "# from statsmodels.tsa.ar_model import ar_select_order\n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "\n",
    "import re\n",
    "res_digit = r'[0-9]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9652555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thisdir = /home/luke/git/external/predicament/notebooks\n",
      "Adding parent directory to python path\n",
      "sys.path =\n",
      "['/home/luke/git/external/predicament/notebooks', '/home/luke/git/external/predicament', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/luke/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "# This is a hack to make the library in the parent folder available for imoprts\n",
    "# A better solution is by np8 here:\n",
    "# https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "thisdir = sys.path[0]\n",
    "print(f\"thisdir = {thisdir}\")\n",
    "parentdir = os.path.dirname(thisdir)\n",
    "#print(f\"parentdir = {parentdir}\")\n",
    "if not parentdir in sys.path:\n",
    "    print(\"Adding parent directory to python path\")\n",
    "    sys.path.insert(1, parentdir)\n",
    "else:\n",
    "    print(\"Skipping adding parent direct to path (there already)\")\n",
    "\n",
    "print(f\"sys.path =\\n{sys.path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f17581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure relative path to data directory is sound\n",
    "# for the notebook we need to modify the BASE_DATA_FOLDER\n",
    "import os \n",
    "os.environ['PREDICAMENT_DATA_DIR'] =  '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd724667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predicament.utils.config import DREEM_EEG_CHANNELS\n",
    "from predicament.utils.config import FEATURED_BASE_PATH\n",
    "from predicament.utils.config import WINDOWED_BASE_PATH\n",
    "\n",
    "\n",
    "from predicament.data.timeseries import create_participant_data_edf_only\n",
    "from predicament.data.windowed import window_all_participants_data\n",
    "from predicament.data.windowed import merge_condition_data\n",
    "from predicament.data.partitioning import between_subject_cv_partition\n",
    "\n",
    "from predicament.data.features import MAXIMAL_FEATURE_GROUP\n",
    "from predicament.data.features import STATS_FEATURE_GROUP\n",
    "from predicament.data.features import INFO_FEATURE_GROUP\n",
    "from predicament.data.features import FREQ_FEATURE_GROUP\n",
    "from predicament.data.features import convert_timeseries_to_features\n",
    "from prepare_evaluation_data import load_dataframe_and_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3596cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VG_01': '../data/CARE_HOME_DATA/./VG01/E4_8921_15_44/',\n",
       " 'VG_03': '../data/CARE_HOME_DATA/./VG03/E4_9921_12_16/',\n",
       " 'VG_05': '../data/CARE_HOME_DATA/./VG05/E4_9921_13_24/',\n",
       " 'VG_06': '../data/CARE_HOME_DATA/./VG06/E4_51021_13_33/',\n",
       " 'VG_07': '../data/CARE_HOME_DATA/./VG07/E4_51021_15_39/',\n",
       " 'VG_08': '../data/CARE_HOME_DATA/./VG08/E4_71021_10_42/',\n",
       " 'VG_09': '../data/CARE_HOME_DATA/./VG09/E4_11221_14_46/',\n",
       " 'VG_10': '../data/CARE_HOME_DATA/./VG10/E4_31221_11_17/',\n",
       " 'VH_01': '../data/CARE_HOME_DATA/./VH01/E4_61021_11_03/',\n",
       " 'VH_02': '../data/CARE_HOME_DATA/./VH02/E4_61021_13_59/',\n",
       " 'VH_03': '../data/CARE_HOME_DATA/./VH03/E4_11221_11_22/'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predicament.utils.config import E4_CSV_FILES\n",
    "from predicament.utils.config import E4_FULL_DIRPATHS\n",
    "E4_FULL_DIRPATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ad333",
   "metadata": {},
   "source": [
    "## Gait data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/other_datasets/uci_multivariate_gait_data/gait.csv\")\n",
    "print(f\"df.shape = {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63593078",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df['subject'].unique()\n",
    "conditions = df['condition'].unique()\n",
    "legs = df['leg'].unique()\n",
    "joints = df['joint'].unique()\n",
    "replications = df['replication'].unique()\n",
    "times = df['time'].unique()\n",
    "print(f\"subjects = {subjects}\")\n",
    "print(f\"conditions = {conditions}\")\n",
    "print(f\"replications = {replications}\")\n",
    "print(f\"joints = {joints}\")\n",
    "print(f\"legs = {legs}\")\n",
    "print(f\"joints = {joints}\")\n",
    "print(f\"times = {times}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682765e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    subject_df = df[df['subject'] == subject]\n",
    "    print(f\"subject {subject}: has {subject_df.shape[0]} datapoints with {subject_df['time'].max()} time-points\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2dabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_c1_r1_df = df[(df['subject'] == 1) &(df['condition'] == 1) &(df['replication'] == 1)]\n",
    "T = times.size\n",
    "n_channels = len(legs)*len(joints)\n",
    "\n",
    "s1_c1_r1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a06ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X111 = np.zeros((n_channels, T))\n",
    "for c,(leg, joint) in enumerate(itertools.product(legs,joints)):\n",
    "    X111[c,:] = s1_c1_r1_df[(s1_c1_r1_df['leg']==leg)&(s1_c1_r1_df['joint']==joint)]['angle'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data looks like it has already been smoothed/filtered so\n",
    "# we will not be applying any filtering to this dataset\n",
    "fig, axs = plt.subplots(n_channels,1)\n",
    "for c,(leg, joint) in enumerate(itertools.product(legs,joints)):\n",
    "    axs[c].plot(times, X111[c,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries(df, subject, condition, replication, legs=None, joints=None):\n",
    "    if legs is None:\n",
    "        legs = df['leg'].unique()\n",
    "    if joints is None:\n",
    "        joints = df['joint'].unique()\n",
    "    X = np.zeros((n_channels, T))\n",
    "    scr_df = df[(df['subject'] == subject) &(df['condition'] == condition) &(df['replication'] == replication)]\n",
    "    for c,(leg, joint) in enumerate(itertools.product(legs,joints)):\n",
    "        X[c,:] = scr_df[(scr_df['leg']==leg)&(scr_df['joint']==joint)]['angle'].to_numpy()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = set(\n",
    "    ['Mean', 'SD', 'MAD', 'Max', 'Min',# 'SMA',\n",
    "     'Energy', 'IQR', 'Entropy',\n",
    "    'arCoeff', 'Correlation', 'Hurst',\n",
    "    'MaxFreqInd', 'MeanFreq', 'FreqSkewness',\n",
    "    'FreqKurtosis'#, 'EnergyBands'\n",
    "    ])\n",
    "entropy_tol = 1\n",
    "output_lol = []\n",
    "scr_cols = ['subject','condition','replication']\n",
    "for subject, condition, replication, in np.unique(df[scr_cols].values, axis=0):\n",
    "    # for each unique subject, condition and replication\n",
    "    X = get_timeseries(df, subject, condition, replication)\n",
    "    features, feature_names = convert_timeseries_to_features(\n",
    "        X, feature_set, entropy_tol=entropy_tol, hurst_kind='random_walk')\n",
    "    output_lol.append(\n",
    "        np.concatenate(\n",
    "            ((subject, condition, replication), features)))\n",
    "all_columns = scr_cols + feature_names\n",
    "output_df = pd.DataFrame(output_lol,columns=all_columns)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"../data/other_datasets/uci_multivariate_gait_data/gait_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777bebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
