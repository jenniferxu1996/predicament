{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44acde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import re\n",
    "res_digit = r'[0-9]'\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832db706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thisdir = /home/luke/git/external/predicament/notebooks\n",
      "Adding parent directory to python path\n",
      "sys.path =\n",
      "['/home/luke/git/external/predicament/notebooks', '/home/luke/git/external/predicament', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/luke/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "# This is a hack to make the library in the parent folder available for imoprts\n",
    "# A better solution is by np8 here:\n",
    "# https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "thisdir = sys.path[0]\n",
    "print(f\"thisdir = {thisdir}\")\n",
    "parentdir = os.path.dirname(thisdir)\n",
    "#print(f\"parentdir = {parentdir}\")\n",
    "if not parentdir in sys.path:\n",
    "    print(\"Adding parent directory to python path\")\n",
    "    sys.path.insert(1, parentdir)\n",
    "else:\n",
    "    print(\"Skipping adding parent direct to path (there already)\")\n",
    "\n",
    "print(f\"sys.path =\\n{sys.path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f17581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure relative path to data directory is sound\n",
    "# for the notebook we need to modify the BASE_DATA_FOLDER\n",
    "import os \n",
    "os.environ['PREDICAMENT_DATA_DIR'] =  '../data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd724667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predicament.utils.file_utils import load_dataframe_and_config\n",
    "import predicament.utils.config_parser\n",
    "reload(predicament.utils.config_parser)\n",
    "from predicament.utils.config_parser import config_to_dict\n",
    "\n",
    "from predicament.utils.config import FEATURED_BASE_PATH\n",
    "from predicament.data.features import IDEAL_FEATURE_GROUP\n",
    "\n",
    "from predicament.evaluation.balancing import get_group_label_counts\n",
    "from predicament.evaluation.balancing import balance_data\n",
    "from predicament.evaluation.grouping import get_group_assignments\n",
    "from predicament.evaluation.staging import get_design_matrix\n",
    "from predicament.evaluation.results import output_model_best_from_results\n",
    "from predicament.evaluation.results import save_results_df_to_file\n",
    "\n",
    "from predicament.evaluation.hyperparameters import get_param_scopes\n",
    "from predicament.evaluation.hyperparameters import get_param_search_object\n",
    "\n",
    "from predicament.models.mlp_wrappers import ThreeHiddenLayerClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd59ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high level choices\n",
    "subdir = 'dreem_4secs' # dataset\n",
    "held_out = 'participant'\n",
    "is_balanced = True # balance data set\n",
    "use_only_ideal_features = True # restrict to preferred ideal features\n",
    "standardise_data = False\n",
    "max_iter_opt = 200\n",
    "n_iter = 50 # number of iterations for your search\n",
    "new_search = True # restarts the search\n",
    "random_state = 43\n",
    "use_callback = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e1a17",
   "metadata": {},
   "source": [
    "## Load featured data and balance if required\n",
    "\n",
    "Before running this, you will need to generate featured data. See README file for details. For the variable `subdir` above replace this with the subdirectory name of the featured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e1ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_data_dir = os.path.join(FEATURED_BASE_PATH,subdir)\n",
    "\n",
    "featured_df, featured_config = load_dataframe_and_config(\n",
    "    featured_data_dir, 'featured.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf468030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_rate: 250, n_samples = 1024, time: 4.096s, n_channels: 4\n"
     ]
    }
   ],
   "source": [
    "n_channels = featured_config['LOAD']['n_channels']\n",
    "data_format = featured_config['LOAD']['data_format']\n",
    "channels = featured_config['LOAD']['channels']\n",
    "participant_list = featured_config['LOAD']['participant_list']\n",
    "sample_rate = featured_config['LOAD']['sample_rate']\n",
    "Fs = sample_rate\n",
    "window_size = featured_config['LOAD']['window_size']\n",
    "time = window_size/sample_rate\n",
    "print(f\"sample_rate: {sample_rate}, n_samples = {window_size}, time: {time}s, n_channels: {n_channels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91ee90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before balancing: subject_condition_counts = [[ 813.  461.  461.  461.  461.]\n",
      " [ 813.  344.  461.  559.  461.]\n",
      " [ 813.  110.  344.  461.  344.]\n",
      " [ 813.  227.  461.  461.  461.]\n",
      " [ 813.  578.  344.  227.  461.]\n",
      " [   0.  110.    0. 1047.  344.]\n",
      " [ 832.  422.    0.  504.  364.]\n",
      " [ 813.  578.  461.  344.   86.]\n",
      " [ 813.  578.    0.  344.  344.]\n",
      " [ 803.  325.    0.  551.  348.]\n",
      " [ 930.  461.  344.  461.  344.]\n",
      " [ 696.  578.  461.  344.  461.]]\n",
      "after balancing: subject_condition_counts = [[304. 322. 461. 283. 296.]\n",
      " [304. 322. 461. 283. 296.]\n",
      " [304. 110. 344. 283. 296.]\n",
      " [304. 227. 461. 283. 296.]\n",
      " [304. 322. 344. 227. 296.]\n",
      " [  0. 110.   0. 283. 296.]\n",
      " [304. 322.   0. 283. 296.]\n",
      " [304. 322. 461. 283.  86.]\n",
      " [304. 322.   0. 283. 296.]\n",
      " [304. 322.   0. 283. 296.]\n",
      " [304. 322. 344. 283. 296.]\n",
      " [304. 322. 461. 283. 296.]]\n"
     ]
    }
   ],
   "source": [
    "if is_balanced:\n",
    "    # balance featured data\n",
    "    subject_condition_counts = get_group_label_counts(featured_df, 'participant', 'condition')\n",
    "    print(f\"before balancing: subject_condition_counts = {subject_condition_counts}\")\n",
    "    featured_df = balance_data(featured_df, group_col='participant', label_col='condition')\n",
    "    subject_condition_counts = get_group_label_counts(featured_df, 'participant', 'condition')\n",
    "\n",
    "    print(f\"after balancing: subject_condition_counts = {subject_condition_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eca41c",
   "metadata": {},
   "source": [
    "## Define model and hyperparamer search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "408a74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator = None\n",
      "param_scopes = {'layer1': Integer(low=10, high=100, prior='uniform', transform='identity'), 'layer2': Integer(low=10, high=100, prior='uniform', transform='identity'), 'layer3': Integer(low=10, high=100, prior='uniform', transform='identity'), 'activation': Categorical(categories=('tanh', 'relu'), prior=None), 'solver': Categorical(categories=('sgd', 'adam'), prior=None), 'alpha': Real(low=1e-06, high=0.01, prior='log-uniform', transform='identity'), 'learning_rate': Categorical(categories=('constant', 'adaptive'), prior=None), 'learning_rate_init': Real(low=1e-06, high=10.0, prior='log-uniform', transform='identity')}\n"
     ]
    }
   ],
   "source": [
    "overrides = dict()\n",
    "excludes = list()\n",
    "# the base model to tune\n",
    "#estimator = SVC()\n",
    "#estimator = GradientBoostingClassifier()\n",
    "#estimator = RandomForestClassifier()\n",
    "# max_iter_opt = 1\n",
    "#estimator = MLPClassifier(max_iter=max_iter_opt)\n",
    "estimator = ThreeHiddenLayerClassifier()\n",
    "# excludes = ['layer3'] # for 2 (hidden) layer MLP (leave empty for 3 layer MLP)\n",
    "#excludes = ['layer2', 'layer3'] # for 1 (hidden) layer MLP\n",
    "print(f\"estimator = {estimator}\")\n",
    "\n",
    "# search_type = 'random_search'\n",
    "search_type = 'bayesian_optimization'\n",
    "\n",
    "# now create the parameter search object and run the hyperparameter search\n",
    "param_scopes = get_param_scopes(\n",
    "    search_type, estimator, excludes=excludes, **overrides)\n",
    "print(f\"param_scopes = {param_scopes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83039b8d",
   "metadata": {},
   "source": [
    "## Define data properties and data-split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9fb7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_set = ['Max', 'MAD', 'Mean', 'SampleEntropy', 'MeanFreq', 'Hurst', 'SD', 'arCoeff', 'LyapunovExponent', 'IQR', 'MaxFreqInd', 'FreqKurtosis', 'LempelZivComplexity', 'Correlation', 'Min']\n"
     ]
    }
   ],
   "source": [
    "feature_set = featured_config['FEATURED']['feature_set']\n",
    "if use_only_ideal_features:\n",
    "    feature_set = list(IDEAL_FEATURE_GROUP.intersection(feature_set))\n",
    "    \n",
    "print(f\"feature_set = {feature_set}\")\n",
    "\n",
    "# extract input data\n",
    "# use all features in file\n",
    "feature_types, feature_names, designmtx = get_design_matrix(\n",
    "    featured_df, feature_set)\n",
    "# extract labels\n",
    "labels = featured_df['condition'].values.astype(int)\n",
    "\n",
    "if standardise_data:\n",
    "    scaler = preprocessing.StandardScaler().fit(designmtx)\n",
    "    designmtx = scaler.transform(designmtx)\n",
    "    \n",
    "# prepare Hold one group out cross validation\n",
    "held_out, groups, group_assignments = get_group_assignments(featured_df)\n",
    "n_groups = len(groups)\n",
    "# cross validation splits    \n",
    "group_kfold = GroupKFold(n_splits=n_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad18edb",
   "metadata": {},
   "source": [
    "## Define and Execute hyperparameter search strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda169a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.10383543300931818\n",
      "Best parameters: ['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.17839607282061778\n",
      "Best parameters: ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.20238222726939595\n",
      "Best parameters: ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.20238222726939595\n",
      "Best parameters: ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.20238222726939595\n",
      "Best parameters: ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.20238222726939595\n",
      "Best parameters: ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.2448831043914348\n",
      "Best parameters: ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.2476009184904738\n",
      "Best parameters: ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Best score: 0.2476009184904738\n",
      "Best parameters: ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.2476009184904738\n",
      "Best parameters: ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd']\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/luke/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate Results:\n",
      "Iteration 1: Scores - [-0.10383543], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 2: Scores - [-0.10383543 -0.17839607], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 3: Scores - [-0.10383543 -0.17839607 -0.20238223], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 4: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 5: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335 -0.18085876], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 6: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335 -0.18085876 -0.09418157], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 7: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335 -0.18085876 -0.09418157\n",
      " -0.2448831 ], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 8: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335 -0.18085876 -0.09418157\n",
      " -0.2448831  -0.24760092], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 9: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335 -0.18085876 -0.09418157\n",
      " -0.2448831  -0.24760092 -0.1507712 ], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n",
      "Iteration 10: Scores - [-0.10383543 -0.17839607 -0.20238223 -0.15722335 -0.18085876 -0.09418157\n",
      " -0.2448831  -0.24760092 -0.1507712  -0.22311007], Params - [['relu', 1.0310736334774332e-05, 30, 49, 90, 'adaptive', 0.1898028832031952, 'sgd'], ['tanh', 0.005885338806523476, 51, 61, 84, 'constant', 0.0011977947293479844, 'sgd'], ['tanh', 0.00012282687710642398, 22, 83, 96, 'adaptive', 8.937120042880887, 'adam'], ['tanh', 8.936224314764104e-06, 53, 79, 72, 'constant', 0.01090658997719509, 'sgd'], ['tanh', 0.00014688992790007224, 55, 43, 89, 'constant', 0.2576363024149079, 'sgd'], ['tanh', 4.468330777342982e-05, 48, 30, 93, 'adaptive', 1.227549197302471, 'sgd'], ['tanh', 2.442583506253724e-06, 73, 85, 37, 'constant', 9.329577004476626, 'sgd'], ['relu', 0.00034973710968534325, 11, 80, 77, 'constant', 2.7824165845586706e-06, 'sgd'], ['relu', 3.487488243540924e-06, 15, 16, 39, 'constant', 0.3054061456018806, 'sgd'], ['relu', 0.0007356479814621087, 74, 85, 63, 'constant', 1.817135908518888e-06, 'adam']]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     param_search\u001b[38;5;241m.\u001b[39mfit_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_results\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m intermediate_results\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Fit the random search model\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mparam_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesignmtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_assignments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException occurred:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/searchcv.py:538\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m     )\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/searchcv.py:595\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 595\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/skopt/searchcv.py:449\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[1;32m    447\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[0;32m--> 449\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fix to avoid error in BayesSearchCV.fit\n",
    "import numpy as np\n",
    "np.int = int\n",
    "\n",
    "def create_callback_and_storage(param_search):\n",
    "    intermediate_results = []\n",
    "    # Define a custom callback function to store intermediate results\n",
    "    def on_step(optim_result):\n",
    "        # Store the current state of the optimization process\n",
    "        intermediate_results.append((optim_result.func_vals, optim_result.x_iters))\n",
    "\n",
    "        # Print out the best score and best parameters found so far\n",
    "        best_score = -optim_result.fun\n",
    "        print(\"Best score: %s\" % best_score)\n",
    "        print(\"Best parameters: %s\" % optim_result.x)\n",
    "    return on_step, intermediate_results\n",
    "\n",
    "\n",
    "param_search  = get_param_search_object(\n",
    "    search_type, estimator, param_scopes=param_scopes, \n",
    "    n_iter = n_iter, cv=group_kfold,\n",
    "    verbose=2, random_state=random_state, n_jobs=-1,\n",
    "    fit_params={'X': designmtx, 'y': labels, 'callbacks': None},\n",
    "    refit=False  # Ensure that the search does not refit the model with the best parameters found so far\n",
    ")\n",
    "\n",
    "if use_callback:\n",
    "    if new_search:\n",
    "        on_step, intermediate_results = create_callback_and_storage(param_search)\n",
    "    else:\n",
    "        param_search.fit_params['search_results'] = intermediate_results\n",
    "    try:\n",
    "        # Fit the random search model\n",
    "        _ = param_search.fit(X=designmtx, y=labels, groups=group_assignments, callback=on_step)\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred:\", str(e))\n",
    "    finally:\n",
    "        # Print or process intermediate results even if an error occurs\n",
    "        print(\"Intermediate Results:\")\n",
    "        for i, (scores, params) in enumerate(intermediate_results):\n",
    "            print(f\"Iteration {i + 1}: Scores - {scores}, Params - {params}\")\n",
    "        new_search = False\n",
    "        random_state = np.random.randint(100000)\n",
    "else:\n",
    "    _ = param_search.fit(X=designmtx, y=labels, groups=group_assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9466e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e5687",
   "metadata": {},
   "source": [
    "## Saving and outputing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(param_search.cv_results_)\n",
    "i = 0\n",
    "result_df.insert(i, 'model', str(estimator))\n",
    "i +=1\n",
    "result_df.insert(i, 'data format', data_format)\n",
    "i +=1\n",
    "result_df.insert(i, 'held out', held_out)\n",
    "i +=1\n",
    "result_df.insert(i, 'balanced', is_balanced)\n",
    "i +=1\n",
    "result_df.insert(i, 'n_splits', param_search.get_params()['cv'].get_n_splits())\n",
    "i +=1\n",
    "result_df.insert(i, 'feature set', str(feature_types))\n",
    "i +=1\n",
    "result_df.insert(i, 'window size', window_size)\n",
    "display(result_df)\n",
    "results_fname = f'{search_type}_{str(estimator)}'\n",
    "print(f\"Saving to {results_fname}\")\n",
    "save_results_df_to_file(result_df, results_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = output_model_best_from_results(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fa9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = featured_config['WINDOWED']['label_cols']\n",
    "feature_types = list(feature_set)\n",
    "feature_types.sort()\n",
    "print(f\"# Feature Set:\\n{feature_types}\")\n",
    "derived_feature_names = []\n",
    "derived_feature_types = set([])\n",
    "for f in featured_df.columns:\n",
    "    if f in label_cols:\n",
    "        continue\n",
    "    elif (f[-1] == ']'):\n",
    "        if (f[:-1].rstrip('0123456789')[-1] == '['):\n",
    "            f = f[:-1].rstrip('0123456789')[:-1]\n",
    "    else:\n",
    "        f = f.rstrip('0123456789')\n",
    "    for type_ in feature_set:\n",
    "        if f.startswith(type_):\n",
    "            derived_feature_types.add(f)\n",
    "            break\n",
    "derived_feature_types = list(derived_feature_types)\n",
    "derived_feature_types.sort()\n",
    "output = ';'.join(derived_feature_types)\n",
    "print(f\"Derived Feature Types:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0,0.3,51)\n",
    "N = len(result_df)\n",
    "props = np.empty(thresholds.size)\n",
    "for t, thresh in enumerate(thresholds):\n",
    "    count = np.sum(result_df['mean_test_score'] > thresh)\n",
    "    props[t] = count/N\n",
    "plt.plot(thresholds, props)\n",
    "plt.xlabel(\"mean test score\")\n",
    "plt.ylabel(\"proportion greater than\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3566f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7bca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [col for col in result_df.columns if col.startswith('param') or (col =='mean_test_score')]\n",
    "result_df[result_df['mean_test_score'] >= 0.225][display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c60452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just show all rows\n",
    "result_df[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc9872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
